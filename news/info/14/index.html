<!DOCTYPE html><html lang="en"><head><meta name="generator" content="React Static"/><meta charSet="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5, shrink-to-fit=no"/><link rel="preload" as="script" href="/templates/styles.0fac0af2.js"/><link rel="preload" as="script" href="/templates/vendors~main.f9fbf9ef.js"/><link rel="preload" as="script" href="/main.a7a8ff5b.js"/><link rel="preload" as="style" href="/styles.82b2ee7c.css"/><link rel="stylesheet" href="/styles.82b2ee7c.css"/></head><body><div id="root"><div style="outline:none" tabindex="-1"><div class="App"><div class="jss2"><div class="jss3"><div class="jss4"><div class="content"><div><h3 class="MuiTypography-root MuiTypography-h3 MuiTypography-alignCenter" style="color:#279DCC;height:80%">南京理工大学智能媒体分析实验室</h3></div><div><p class="MuiTypography-root MuiTypography-body1 MuiTypography-gutterBottom" style="color:#666666;margin-bottom:25px">Intelligent Media Analysis Group (IMAG), School of Computer Science, Nanjing University of Science and Technology</p></div></div></div></div><div class="jss6"><header class="MuiPaper-root MuiAppBar-root MuiAppBar-positionStatic MuiAppBar-colorPrimary jss9 MuiPaper-elevation4"><div class="MuiToolbar-root MuiToolbar-regular MuiToolbar-gutters"><div class="jss11"><div class="jss13"><div style="background-color:white"><a style="color:#57247b;padding-left:20px;padding-right:20px;line-height:64px" href="/">HOME</a></div><div style="background-color:"><a style="color:white;padding-left:20px;padding-right:20px;line-height:64px" href="/people">PEOPLE</a></div><div style="background-color:"><a style="color:white;padding-left:20px;padding-right:20px;line-height:64px" href="/news">NEWS</a></div><div><button class="MuiButtonBase-root MuiButton-root MuiButton-text" tabindex="0" type="button" style="top:-2px;font-size:16px;font-weight:bold;padding-left:20px;padding-right:20px;line-height:46px;background-color:;color:white" aria-haspopup="true"><span class="MuiButton-label">PUBLICATION</span></button></div><div style="background-color:"><a style="color:white;padding-left:20px;padding-right:20px;line-height:64px" href="/grants">GRANTS</a></div><div style="background-color:"><a style="color:white;padding-left:20px;padding-right:20px;line-height:64px" href="/resource">RESOURCE</a></div><div style="background-color:"><a style="color:white;padding-left:20px;padding-right:20px;line-height:64px" href="/contact">CONTACT</a></div></div></div></div></header></div><div class="jss5"><div style="outline:none" tabindex="-1"><div class="jss34"><div class="jss36"><h3 class="MuiTypography-root MuiTypography-h3 MuiTypography-alignCenter" style="padding-top:50px;padding-bottom:10px">研究室的一篇跨媒体关联学习论文被IJCV接收为Regular论文</h3><div><p>&emsp;&emsp;研究室的一篇跨媒体关联学习论文被IJCV接收为Regular论文：Yuxin Peng, Jinwei Qi, Zhaoda Ye and Yunkan Zhuo, "Hierarchical Visual-Textual Knowledge Distillation for Life-Long Correlation Learning", International Journal of Computer Vision (IJCV), Oct. 2020。祝贺綦金玮、叶钊达和卓昀侃！
&emsp;&emsp;多媒体数据的关联学习面临跨模态和跨域两方面的挑战。现有方法常常只考虑多媒体数据的跨模态问题，但忽视了跨域对关联学习带来的影响。为此，我们提出了基于多层次视觉-文本知识蒸馏的终身学习方法，能够同时解决关联学习中的跨模态与跨域挑战。针对关联学习中的跨模态问题，我们提出了多层次的视觉-文本循环神经网络，能够挖掘图像和文本中全局和局部的细粒度上下文信息，为跨模态关联学习提供多层级的语义信息。针对关联学习中的跨域问题，提出了基于终生学习的模型训练策略，不同于现有方法需要对新域数据重新训练整个模型，该论文通过可扩展的模型结构，仅仅需要重新训练与新域相关的少量参数，实现了单个模型同时对不同域的多媒体数据的关联学习。此外提出了媒体间注意力层级的知识迁移和域间语义层级的知识迁移策略，充分利用不同模态以及不同域中知识的互补性，促进了跨模态和跨域数据的关联学习。</p></div></div></div></div></div></div></div><div class="jss7"><div class="jss8"><div><p class="MuiTypography-root MuiTypography-body1" style="color:#ffffff">Copyright © 2022 南京理工大学智能媒体分析实验室. All rights reserved.</p></div><div><p class="MuiTypography-root MuiTypography-body1 MuiTypography-gutterBottom" style="color:#ffffff">Theme: ColorMag by ThemeGrill. Powered by WordPress.</p></div></div></div></div></div><script type="text/javascript">window.__routeInfo = JSON.parse("{\"template\":\"react_static_root__/src/containers/newsPage\",\"sharedHashesByProp\":{},\"data\":{\"newItem\":{\"title\":\"\u7814\u7A76\u5BA4\u7684\u4E00\u7BC7\u8DE8\u5A92\u4F53\u5173\u8054\u5B66\u4E60\u8BBA\u6587\u88ABIJCV\u63A5\u6536\u4E3ARegular\u8BBA\u6587\",\"publisher\":\"\",\"content\":\"<p>&emsp;&emsp;\u7814\u7A76\u5BA4\u7684\u4E00\u7BC7\u8DE8\u5A92\u4F53\u5173\u8054\u5B66\u4E60\u8BBA\u6587\u88ABIJCV\u63A5\u6536\u4E3ARegular\u8BBA\u6587\uFF1AYuxin Peng, Jinwei Qi, Zhaoda Ye and Yunkan Zhuo, \\\"Hierarchical Visual-Textual Knowledge Distillation for Life-Long Correlation Learning\\\", International Journal of Computer Vision (IJCV), Oct. 2020\u3002\u795D\u8D3A\u7DA6\u91D1\u73AE\u3001\u53F6\u948A\u8FBE\u548C\u5353\u6600\u4F83\uFF01\\n&emsp;&emsp;\u591A\u5A92\u4F53\u6570\u636E\u7684\u5173\u8054\u5B66\u4E60\u9762\u4E34\u8DE8\u6A21\u6001\u548C\u8DE8\u57DF\u4E24\u65B9\u9762\u7684\u6311\u6218\u3002\u73B0\u6709\u65B9\u6CD5\u5E38\u5E38\u53EA\u8003\u8651\u591A\u5A92\u4F53\u6570\u636E\u7684\u8DE8\u6A21\u6001\u95EE\u9898\uFF0C\u4F46\u5FFD\u89C6\u4E86\u8DE8\u57DF\u5BF9\u5173\u8054\u5B66\u4E60\u5E26\u6765\u7684\u5F71\u54CD\u3002\u4E3A\u6B64\uFF0C\u6211\u4EEC\u63D0\u51FA\u4E86\u57FA\u4E8E\u591A\u5C42\u6B21\u89C6\u89C9-\u6587\u672C\u77E5\u8BC6\u84B8\u998F\u7684\u7EC8\u8EAB\u5B66\u4E60\u65B9\u6CD5\uFF0C\u80FD\u591F\u540C\u65F6\u89E3\u51B3\u5173\u8054\u5B66\u4E60\u4E2D\u7684\u8DE8\u6A21\u6001\u4E0E\u8DE8\u57DF\u6311\u6218\u3002\u9488\u5BF9\u5173\u8054\u5B66\u4E60\u4E2D\u7684\u8DE8\u6A21\u6001\u95EE\u9898\uFF0C\u6211\u4EEC\u63D0\u51FA\u4E86\u591A\u5C42\u6B21\u7684\u89C6\u89C9-\u6587\u672C\u5FAA\u73AF\u795E\u7ECF\u7F51\u7EDC\uFF0C\u80FD\u591F\u6316\u6398\u56FE\u50CF\u548C\u6587\u672C\u4E2D\u5168\u5C40\u548C\u5C40\u90E8\u7684\u7EC6\u7C92\u5EA6\u4E0A\u4E0B\u6587\u4FE1\u606F\uFF0C\u4E3A\u8DE8\u6A21\u6001\u5173\u8054\u5B66\u4E60\u63D0\u4F9B\u591A\u5C42\u7EA7\u7684\u8BED\u4E49\u4FE1\u606F\u3002\u9488\u5BF9\u5173\u8054\u5B66\u4E60\u4E2D\u7684\u8DE8\u57DF\u95EE\u9898\uFF0C\u63D0\u51FA\u4E86\u57FA\u4E8E\u7EC8\u751F\u5B66\u4E60\u7684\u6A21\u578B\u8BAD\u7EC3\u7B56\u7565\uFF0C\u4E0D\u540C\u4E8E\u73B0\u6709\u65B9\u6CD5\u9700\u8981\u5BF9\u65B0\u57DF\u6570\u636E\u91CD\u65B0\u8BAD\u7EC3\u6574\u4E2A\u6A21\u578B\uFF0C\u8BE5\u8BBA\u6587\u901A\u8FC7\u53EF\u6269\u5C55\u7684\u6A21\u578B\u7ED3\u6784\uFF0C\u4EC5\u4EC5\u9700\u8981\u91CD\u65B0\u8BAD\u7EC3\u4E0E\u65B0\u57DF\u76F8\u5173\u7684\u5C11\u91CF\u53C2\u6570\uFF0C\u5B9E\u73B0\u4E86\u5355\u4E2A\u6A21\u578B\u540C\u65F6\u5BF9\u4E0D\u540C\u57DF\u7684\u591A\u5A92\u4F53\u6570\u636E\u7684\u5173\u8054\u5B66\u4E60\u3002\u6B64\u5916\u63D0\u51FA\u4E86\u5A92\u4F53\u95F4\u6CE8\u610F\u529B\u5C42\u7EA7\u7684\u77E5\u8BC6\u8FC1\u79FB\u548C\u57DF\u95F4\u8BED\u4E49\u5C42\u7EA7\u7684\u77E5\u8BC6\u8FC1\u79FB\u7B56\u7565\uFF0C\u5145\u5206\u5229\u7528\u4E0D\u540C\u6A21\u6001\u4EE5\u53CA\u4E0D\u540C\u57DF\u4E2D\u77E5\u8BC6\u7684\u4E92\u8865\u6027\uFF0C\u4FC3\u8FDB\u4E86\u8DE8\u6A21\u6001\u548C\u8DE8\u57DF\u6570\u636E\u7684\u5173\u8054\u5B66\u4E60\u3002</p>\",\"dat\":null,\"classify\":\"\",\"id\":14}},\"path\":\"news/info/14\",\"sharedData\":{},\"siteData\":{}}");</script><script defer="" type="text/javascript" src="/templates/styles.0fac0af2.js"></script><script defer="" type="text/javascript" src="/templates/vendors~main.f9fbf9ef.js"></script><script defer="" type="text/javascript" src="/main.a7a8ff5b.js"></script></body></html>