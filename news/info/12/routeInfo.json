{"template":"react_static_root__/src/containers/newsPage","sharedHashesByProp":{},"data":{"newItem":{"title":"研究室的一篇跨媒体检索论文被TCSVT接收","publisher":"","content":"<p>研究室的一篇跨媒体检索论文被TCSVT接收为Regular论文: Yunbo Wang and Yuxin Peng, \"MARS: Learning Modality-Agnostic Representation for Scalable Cross-media Retrieval\", IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2021。祝贺王运波博士！\n  现有方法在训练时受限于成对的跨媒体数据，当新增一种媒体类型时，需要再次训练现有媒体类型的数据，削弱了跨媒体检索的灵活性。针对上述问题，提出了一种媒体类型无关的表示学习方法，支持每种媒体数据独立学习判别性表示，进而实现跨媒体检索。将标签信息视为一种特殊的模态，引入标签解析模块得到标签语义表示以关联不同媒体数据； 同时，构建特定媒体的表示模块获取其语义共享表示。当新增媒体类型时，以已经学习到的标签语义表示作为特权表示来引导新增媒体数据的训练。此外，一个统一的分类器被用于不同媒体数据的表示模块，促进不同媒体数据共享表示的语义对齐，提高了跨媒体检索的有效性和灵活性。</p>","dat":null,"classify":"","id":12}},"path":"news/info/12"}
