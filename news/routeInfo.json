{"template":"react_static_root__/src/pages/news.js","sharedHashesByProp":{},"data":{"detail_news":{"status":1,"news":[{"title":"研究室的一篇跨媒体检索论文被TCSVT接收","publisher":"","content":"<p>研究室的一篇跨媒体检索论文被TCSVT接收为Regular论文: Yunbo Wang and Yuxin Peng, \"MARS: Learning Modality-Agnostic Representation for Scalable Cross-media Retrieval\", IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2021。祝贺王运波博士！\n  现有方法在训练时受限于成对的跨媒体数据，当新增一种媒体类型时，需要再次训练现有媒体类型的数据，削弱了跨媒体检索的灵活性。针对上述问题，提出了一种媒体类型无关的表示学习方法，支持每种媒体数据独立学习判别性表示，进而实现跨媒体检索。将标签信息视为一种特殊的模态，引入标签解析模块得到标签语义表示以关联不同媒体数据； 同时，构建特定媒体的表示模块获取其语义共享表示。当新增媒体类型时，以已经学习到的标签语义表示作为特权表示来引导新增媒体数据的训练。此外，一个统一的分类器被用于不同媒体数据的表示模块，促进不同媒体数据共享表示的语义对齐，提高了跨媒体检索的有效性和灵活性。</p>","dat":null,"classify":"","id":12},{"title":"研究室的一篇跨媒体关联学习论文被IJCV接收为Regular论文","publisher":"","content":"<p>&emsp;&emsp;研究室的一篇跨媒体关联学习论文被IJCV接收为Regular论文：Yuxin Peng, Jinwei Qi, Zhaoda Ye and Yunkan Zhuo, \"Hierarchical Visual-Textual Knowledge Distillation for Life-Long Correlation Learning\", International Journal of Computer Vision (IJCV), Oct. 2020。祝贺綦金玮、叶钊达和卓昀侃！\n&emsp;&emsp;多媒体数据的关联学习面临跨模态和跨域两方面的挑战。现有方法常常只考虑多媒体数据的跨模态问题，但忽视了跨域对关联学习带来的影响。为此，我们提出了基于多层次视觉-文本知识蒸馏的终身学习方法，能够同时解决关联学习中的跨模态与跨域挑战。针对关联学习中的跨模态问题，我们提出了多层次的视觉-文本循环神经网络，能够挖掘图像和文本中全局和局部的细粒度上下文信息，为跨模态关联学习提供多层级的语义信息。针对关联学习中的跨域问题，提出了基于终生学习的模型训练策略，不同于现有方法需要对新域数据重新训练整个模型，该论文通过可扩展的模型结构，仅仅需要重新训练与新域相关的少量参数，实现了单个模型同时对不同域的多媒体数据的关联学习。此外提出了媒体间注意力层级的知识迁移和域间语义层级的知识迁移策略，充分利用不同模态以及不同域中知识的互补性，促进了跨模态和跨域数据的关联学习。</p>","dat":null,"classify":"","id":14},{"title":"测试新闻上传","publisher":"项","content":"<p>新闻测试</p>","dat":null,"classify":"1","id":15}]}},"path":"news"}
